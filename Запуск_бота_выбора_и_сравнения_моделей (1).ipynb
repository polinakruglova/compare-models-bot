{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVB6y9-pjsxL"
      },
      "source": [
        "Установка необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NztNvmESYA6Z",
        "outputId": "edd85fd6-2b88-4ab4-c6d4-fd1d932b7bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pydantic 2.5.3\n",
            "Uninstalling pydantic-2.5.3:\n",
            "  Successfully uninstalled pydantic-2.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aiogram 3.4.1 requires pydantic<2.6,>=2.4.1, but you have pydantic 2.7.4 which is incompatible.\n",
            "albumentations 2.0.6 requires pydantic>=2.9.2, but you have pydantic 2.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.24 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.5.3 which is incompatible.\n",
            "albumentations 2.0.6 requires pydantic>=2.9.2, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y pydantic\n",
        "!pip install -q pydantic==2.7.4\n",
        "!pip install -q aiogram==3.4.1 python-dotenv openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-IyKvyxjy9o"
      },
      "source": [
        "Подготовка ключей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG0ABUGuXI6o"
      },
      "outputs": [],
      "source": [
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(\"TOKEN=YOUR_TOKEN\")\n",
        "    f.write(\"OPENAI_API_KEY=YOUR_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJO7fd2zXPQc",
        "outputId": "560c758e-3b57-4a85-8c89-00da7116f523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKEN: 7938278322:AAEN6dxb_XG5h536E9SJTY8YNyhAX0K1cpY\n",
            "OPENAI_API_KEY: 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\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "print(\"TOKEN:\", os.getenv(\"TOKEN\"))\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thbW6_9RdNqf"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "TOKEN = os.getenv(\"TOKEN\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kpDrW_lu5y"
      },
      "source": [
        "НЕОБХОДИМО СКАЧАТЬ БАЗУ ДАННЫХ database.db (ПРИКРЕПЛЕНА В ПАПКЕ) В СВОЙ ДИСК"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EizAqkpPiG0a",
        "outputId": "52e2d30f-b7de-4883-fda0-28a52ef437cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHHP91WeiPu2",
        "outputId": "e4a62cab-e1c0-446d-9d09-5e46faf757a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/database.db': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp /content/database.db /content/drive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rvfzxASmEpE"
      },
      "source": [
        "Код для запуска сценария бота"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hqfeq4OQ8z2"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import sqlite3\n",
        "import difflib\n",
        "from openai import OpenAI\n",
        "from aiogram import Bot, Dispatcher, types, Router\n",
        "from aiogram.filters import CommandStart\n",
        "from aiogram.fsm.context import FSMContext\n",
        "from aiogram.fsm.state import StatesGroup, State\n",
        "\n",
        "# Инициализация OpenAI\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Инициализация бота\n",
        "bot = Bot(token=TOKEN)\n",
        "dp = Dispatcher()\n",
        "\n",
        "# Роутер для личных сообщений\n",
        "user_private_router = Router()\n",
        "\n",
        "# Подключение к базе данных\n",
        "def connect_db():\n",
        "    return sqlite3.connect(\"/content/drive/MyDrive/database.db\")\n",
        "\n",
        "# Состояния FSM\n",
        "class ModelSelection(StatesGroup):\n",
        "    choosing_model = State()\n",
        "    confirming_choice = State()\n",
        "\n",
        "# Хранилище выбранных моделей\n",
        "user_selected_models = {}\n",
        "\n",
        "# Поиск моделей по запросу\n",
        "def search_models(query):\n",
        "    conn = connect_db()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"SELECT name FROM models WHERE name LIKE ?\", (f\"%{query}%\",))\n",
        "    results = [row[0] for row in cursor.fetchall()]\n",
        "    if results:\n",
        "        conn.close()\n",
        "        return results\n",
        "\n",
        "    cursor.execute(\"SELECT name FROM models\")\n",
        "    all_models = [row[0] for row in cursor.fetchall()]\n",
        "    conn.close()\n",
        "\n",
        "    closest_matches = difflib.get_close_matches(query, all_models, n=5, cutoff=0.5)\n",
        "    return closest_matches if closest_matches else None\n",
        "\n",
        "# Проверка наличия модели\n",
        "def is_model_in_db(model_name):\n",
        "    try:\n",
        "        conn = connect_db()\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT id FROM models WHERE name = ?\", (model_name,))\n",
        "        result = cursor.fetchone()\n",
        "        conn.close()\n",
        "        return result is not None\n",
        "    except sqlite3.Error as e:\n",
        "        print(\"Ошибка БД:\", e)\n",
        "        return False\n",
        "\n",
        "# Получение характеристик\n",
        "def get_model_specifications(model_name):\n",
        "    try:\n",
        "        conn = connect_db()\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT specification_name, specification_value\n",
        "            FROM specifications\n",
        "            WHERE model_id = (SELECT id FROM models WHERE name = ?)\n",
        "        \"\"\", (model_name,))\n",
        "        result = cursor.fetchall()\n",
        "        conn.close()\n",
        "        return result\n",
        "    except sqlite3.Error as e:\n",
        "        print(\"Ошибка характеристик:\", e)\n",
        "        return []\n",
        "\n",
        "# Обращение к GPT\n",
        "async def chat_with_gpt(prompt):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Ты — помощник, который анализирует и сравнивает модели смартфонов.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(\"Ошибка OpenAI:\", e)\n",
        "        return \"Произошла ошибка при обращении к AI.\"\n",
        "\n",
        "# Анализ одной модели\n",
        "async def analyze_single_model(model_name):\n",
        "    if not is_model_in_db(model_name):\n",
        "        return f\"Модель '{model_name}' отсутствует в базе.\"\n",
        "\n",
        "    specs = get_model_specifications(model_name)\n",
        "    if not specs:\n",
        "        return f\"Нет характеристик для модели '{model_name}'.\"\n",
        "\n",
        "    specs_text = \", \".join([f\"{name}: {value}\" for name, value in specs])\n",
        "    prompt = f\"Проанализируй модель '{model_name}' с характеристиками: {specs_text}.\"\n",
        "    analysis = await chat_with_gpt(prompt)\n",
        "    return f\"Анализ модели '{model_name}':\\n{analysis}\"\n",
        "\n",
        "# Сравнение нескольких моделей\n",
        "async def compare_models(model_names):\n",
        "    models_not_found = [model for model in model_names if not is_model_in_db(model)]\n",
        "    if models_not_found:\n",
        "        return f\"Отсутствуют в базе: {', '.join(models_not_found)}\"\n",
        "\n",
        "    comparison_data = {\n",
        "        model: dict(get_model_specifications(model)) for model in model_names\n",
        "    }\n",
        "\n",
        "    prompt = f\"Сравни модели: {comparison_data}\"\n",
        "    comparison = await chat_with_gpt(prompt)\n",
        "    return f\"Сравнение моделей:\\n{comparison}\"\n",
        "\n",
        "# Обработчики состояний\n",
        "@user_private_router.message(CommandStart())\n",
        "async def send_welcome(message: types.Message, state: FSMContext):\n",
        "    user_selected_models[message.from_user.id] = []\n",
        "    await message.reply(\"Введите название модели (можно с ошибками).\")\n",
        "    await state.set_state(ModelSelection.choosing_model)\n",
        "\n",
        "@user_private_router.message(ModelSelection.choosing_model)\n",
        "async def handle_model_input(message: types.Message, state: FSMContext):\n",
        "    user_query = message.text.strip()\n",
        "    if user_query == \".\":\n",
        "        models = user_selected_models.get(message.from_user.id, [])\n",
        "        if models:\n",
        "            if len(models) == 1:\n",
        "                specs = get_model_specifications(models[0])\n",
        "                text = \"\\n\".join([f\"{name}: {value}\" for name, value in specs])\n",
        "                await message.reply(f\"📱 Характеристики *{models[0]}*:\\n{text}\", parse_mode=\"Markdown\")\n",
        "            else:\n",
        "                comparison = await compare_models(models)\n",
        "                await message.reply(comparison)\n",
        "        else:\n",
        "            await message.reply(\"Вы не выбрали ни одной модели.\")\n",
        "\n",
        "        user_selected_models[message.from_user.id] = []\n",
        "        await state.clear()\n",
        "        await message.reply(\"Если хотите начать заново — /start.\")\n",
        "        return\n",
        "\n",
        "    found = search_models(user_query)\n",
        "    if found:\n",
        "        await state.update_data(found_models=found)\n",
        "        text = \"Выберите модель, введя её номер:\\n\" + \"\\n\".join([f\"{i+1}. {m}\" for i, m in enumerate(found)])\n",
        "        await message.reply(text)\n",
        "        await state.set_state(ModelSelection.confirming_choice)\n",
        "    else:\n",
        "        await message.reply(\"Модель не найдена. Попробуйте снова.\")\n",
        "\n",
        "@user_private_router.message(ModelSelection.confirming_choice)\n",
        "async def handle_model_selection(message: types.Message, state: FSMContext):\n",
        "    user_data = await state.get_data()\n",
        "    found_models = user_data.get(\"found_models\", [])\n",
        "\n",
        "    try:\n",
        "        idx = int(message.text.strip()) - 1\n",
        "        if 0 <= idx < len(found_models):\n",
        "            selected = found_models[idx]\n",
        "            user_selected_models[message.from_user.id].append(selected)\n",
        "            await message.reply(f\"✅ Вы выбрали: {selected}\\nВведите следующую модель или '.' для завершения.\")\n",
        "            await state.set_state(ModelSelection.choosing_model)\n",
        "        else:\n",
        "            await message.reply(\"Номер вне диапазона.\")\n",
        "    except ValueError:\n",
        "        await message.reply(\"Введите номер из списка.\")\n",
        "\n",
        "# Подключение роутера\n",
        "dp.include_router(user_private_router)\n",
        "\n",
        "# Запуск бота\n",
        "async def main():\n",
        "    await bot.delete_webhook(drop_pending_updates=True)\n",
        "    await dp.start_polling(bot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIBg3BrwmlMn"
      },
      "source": [
        "Запустить телеграмм бота"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDpCalFydcOe"
      },
      "outputs": [],
      "source": [
        "await main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}